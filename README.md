# Human-Activity-Recoginition

Data Source: UTD-MHAD
Dataset was collected as part of research on human action recognition using fusion of depth and inertial sensor data. The objective of this research has been to develop algorithms for more robust human action recognition using fusion of data from differing modality sensors.

The goal of this project is to recognize and predict human actions from videos. A regular deep neural network would not suit this task for two main reasons: First, deep neural networks do not support handling translation or other distortions of the input, which happen frequently in action videos. Second, deep feed-forward neural networks do not have a state, therefore making processing of videos difficult as they require handling of states in order to recognize or predict actions.

### Prosposed Model
